# Week 07: RAG + LLM + Streamlit (Lab 06)

## üìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ

| ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠ | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î |
|--------|------------|
| **‡∏ß‡∏¥‡∏ä‡∏≤** | CSI403 - Full Stack RAG with Local LLM |
| **Week** | Week 07 |
| **Lab** | Lab 06 |
| **‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠** | RAG Pipeline + Ollama + Streamlit UI |
| **‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô** | 3.75% |
| **Deadline** | ‡∏î‡∏π‡πÉ‡∏ô GitHub Classroom |

---

## üéØ ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå

‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ó‡∏≥ Lab ‡∏ô‡∏µ‡πâ‡πÄ‡∏™‡∏£‡πá‡∏à ‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏à‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ:

1. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Ollama ‡πÑ‡∏î‡πâ
2. ‡∏™‡∏£‡πâ‡∏≤‡∏á RAG Pipeline ‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÑ‡∏î‡πâ
3. ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö Prompt Template ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö RAG ‡πÑ‡∏î‡πâ
4. ‡∏™‡∏£‡πâ‡∏≤‡∏á Streamlit UI ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö chatbot ‡πÑ‡∏î‡πâ

---

## üìù ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥

### Task 1: Ollama Client (25 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)

‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå `src/ollama_client.py` ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏ï‡∏≤‡∏° TODO:

1. **TODO 1**: Implement `generate()` - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å prompt
2. **TODO 2**: Implement `chat()` - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö chat
3. **TODO 3**: Implement `is_available()` - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Ollama ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### Task 2: RAG Pipeline (35 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)

‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå `src/rag_pipeline.py` ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏ï‡∏≤‡∏° TODO:

1. **TODO 1**: ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt Template
2. **TODO 2**: Implement `retrieve()` - ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ documents ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
3. **TODO 3**: Implement `generate_answer()` - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å context
4. **TODO 4**: Implement `query()` - ‡∏£‡∏ß‡∏° retrieve + generate

### Task 3: Streamlit App (30 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)

‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå `src/app.py` ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏ï‡∏≤‡∏° TODO:

1. **TODO 1**: ‡∏™‡∏£‡πâ‡∏≤‡∏á chat interface
2. **TODO 2**: ‡πÅ‡∏™‡∏î‡∏á sources ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
3. **TODO 3**: ‡πÄ‡∏û‡∏¥‡πà‡∏° sidebar settings

### Task 4: Screenshot (10 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)

‡∏ñ‡πà‡∏≤‡∏¢ screenshot ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á app

---

## üöÄ ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏≥ Lab

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Ollama

```bash
# Windows: ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å https://ollama.ai
# Mac:
brew install ollama

# ‡πÄ‡∏£‡∏¥‡πà‡∏° Ollama server
ollama serve
```

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î Model

```bash
ollama pull qwen2.5:7b
```

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 3: Clone ‡πÅ‡∏•‡∏∞ Setup

```bash
git clone <URL ‡∏Ç‡∏≠‡∏á repo ‡∏Ñ‡∏∏‡∏ì>
cd week07-rag-llm-streamlit-<username>

python -m venv venv
venv\Scripts\activate  # Windows
pip install -r requirements.txt
```

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏£‡∏±‡∏ô OpenSearch

```bash
docker-compose up -d
```

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 5: ‡∏ó‡∏≥ Tasks

‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô `src/`

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 6: ‡∏£‡∏±‡∏ô Tests

```bash
pytest tests/ -v
```

### ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 7: ‡∏£‡∏±‡∏ô Streamlit App

```bash
streamlit run src/app.py
```

---

## ‚úÖ ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô (Rubric)

| ‡πÄ‡∏Å‡∏ì‡∏ë‡πå | ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô | ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î |
|-------|-------|------------|
| **Task 1: ollama_client.py** | 25 | Ollama integration ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô |
| **Task 2: rag_pipeline.py** | 35 | RAG pipeline ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå |
| **Task 3: app.py** | 30 | Streamlit UI ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô |
| **Task 4: Screenshots** | 10 | ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô |
| **‡∏£‡∏ß‡∏°** | **100** | |

---

## üìö ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ

> **[‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ]**
> 
> ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Lab ‡∏ô‡∏µ‡πâ ‡πÄ‡∏ä‡πà‡∏ô:
> - Ollama ‡πÅ‡∏•‡∏∞ Local LLM
> - RAG Pipeline design
> - Prompt Engineering
> - Streamlit components
> 
> (‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á)

---

## üìñ ‡πÅ‡∏´‡∏•‡πà‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°

- [Ollama Documentation](https://ollama.ai)
- [Streamlit Documentation](https://docs.streamlit.io)
- [Prompt Engineering Guide](https://www.promptingguide.ai)

---

## ‚ùì ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠?

- ‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô LINE ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ß‡∏¥‡∏ä‡∏≤
- ‡πÄ‡∏õ‡∏¥‡∏î Issue ‡πÉ‡∏ô Repository ‡∏ô‡∏µ‡πâ
- ‡∏û‡∏ö‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå‡πÉ‡∏ô‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á Office Hours

---

**¬© 2026 CSI403 - Full Stack RAG with Local LLM**
